# LLM 时代的 AI

2020s，AI的发展已经来到了LLM时代，以Tansformer架构为基础的AI带来了可用于生产力的落地应用，虽然还处于起步阶段，但终于让世人看到了AI应用的大规模爆发的可能性。

LLM时代的AI的核心有三点：<mark>算法</mark>、<mark>算力</mark>、<mark>数据</mark>。在发展的早期，算法非常关键，但随着时间的推移，尤其是开源LLM的出现，任何能连接互联网下载开源模型的人都可以获得一个效果不俗的LLM，因此算法已经不再是最关键的部分。算力在刚出现杀手级应用如OpenAI的chatgpt时是稀世珍宝，Scaling Law也被奉为圭臬，但是随着时间的推移，并没有更多的杀手级应用如雨后春笋般涌现，但是算力的生产从未停下脚步，截至2024年末，算力的租赁价格差不多只有此前峰值的十分之一不到，因此算力也已经不再是最关键的部分。<strong>从长期来看，真正最有价值也是最核心的部分就是<mark>数据</mark>。</strong>

无论是LLM时代的AI还是此前的各种机器学习算法，本质都是依靠统计学对大数据进行标注，然后投喂给算法模型并进行不断调参优化，那么数据对于AI模型就如同课本对于学生，更优质的数据就能训练出更优质的AI模型。LLM时代诞生了又一次信息指数级的爆炸式增长，AIGC数据充斥在互联网上，这也是各种AI模型为了训练而爬取数据的最主要场所。但是刊登在Nature上的一篇<a href="https://www.nature.com/articles/s41586-024-07566-y" target="_blank">论文</a>中指出，使用AIGC数据训练出的模型效果非常差，Nature的封面也使用了一个呕吐的机器人🤖表明，喂AIGC数据给AI模型就如同给孩子吃垃圾食品，孩子都要吐了。（见下图↓）
<div align="center">
  <img src="https://media.springernature.com/w440/springer-static/cover-hires/journal/41586/631/8022" alt="Garbage Out" width="300" />
</div>
因此，分布在各领域的被人类专家筛选并整理出的带标签的数据才是精华，自然也是各大AI模型眼中的瑰宝，未来谁能控制这些数据，谁就拥有一座AI时代的无尽宝藏。

2024诺贝尔物理学、化学奖全部颁发给AI领域的研究，再叠加商业媒体和各行各业对AI的渲染，未来AI时代的人类社会究竟走向何处被描绘得扑朔迷离。但是看清迷雾的最佳方法就是深入原理，当前主流的AI模型究竟使用了什么技术？关键是使用了<mark>反向传播算法</mark>，这种算法不断根据输出结果调整输入结构，用以达到最佳输出。<strong>但是人类大脑处理相同问题时并没有使用这种算法，因此二者的差异还是非常巨大的。</strong>在此可以得出结论，AI模型与人类思考问题的方式是完全不同的，因此不必担心AI会彻底取代人类，但是对于一些基础性的任务，使用AI来替代人工依然是大势所趋。

那么AI能怎样辅助人类社会向着更好的方向发展呢？以饱受争议的2024年诺贝尔物理学奖作为背景，当前人类研究线性关系的物理学相对容易，例如万有引力定律，研究非线性关系的物理学非常困难，例如湍流问题。大型AI模型对在研究大规模的变量互相作用的非线性关系的物理系统中的帮助是非常巨大的，例如如何将各个物理微观现象统一在一个宏观系统中，也就是物理学的终极理想“大一统理论”，这相当于借用了AI模型对大数据的统计和归纳能力。

总结，由于和人类思考问题的底层原理完全不同，因此在没有能够完全模拟人类大脑的AI模型出现前，对AI模型的担忧就是杞人忧天，AI对于人类来说就是一种更强大的工具，关键还是看这个工具尤其是数据掌握在谁的手中，以及掌握这种资源的人想要做什么样的事情。最后，将我与GPT-4o模型关于“人机协作”话题的讨论放在下方：

<div style="border: 1px solid #ccc; padding: 10px;">
	<span style="color: red;">
		你是谁？
	</span>
</div>
<div style="border: 1px solid #ccc; padding: 10px;">
	<span style="color: blue;">
		我是ChatGPT，一个由OpenAI训练的大型语言模型，旨在帮助用户回答问题、提供建议、进行创作和解决各种问题。如果你有任何问题或需要帮助，请随时告诉我！
	</span>
</div>
<div style="border: 1px solid #ccc; padding: 10px;">
	<span style="color: red;">
		你是否了解构成你自己的这种模型的基本理论？
	</span>
</div>
<div style="border: 1px solid #ccc; padding: 10px;">
	<span style="color: blue;">
		是的，我可以解释一些构成我自己的模型的基本理论。ChatGPT 是基于一种被称为“大语言模型”的技术，这种模型通过大量的数据和先进的深度学习方法进行训练。以下是一些核心的概念和理论：

1. 深度学习与神经网络
我使用的是深度神经网络，具体来说是Transformer 架构。这种架构由 Google 在 2017 年提出，在论文《Attention is All You Need》中详细描述。Transformer 模型擅长处理序列数据，如文本，利用注意力机制来关注输入文本中的不同部分，从而捕捉语言的上下文和含义。

2. 注意力机制
自注意力机制（Self-Attention）是 Transformer 的核心组成部分。它允许模型在处理句子中的每个单词时，同时考虑该句子中的所有其他单词，从而更好地理解文本的整体含义。

3. 预训练和微调
我的模型是通过一种称为预训练和微调的过程训练的。预训练阶段使用大量的互联网数据，通过自监督学习来预测文本中缺失的单词或生成下一段文本。在微调阶段，模型在更小的、特定领域的数据集上进一步调整，以提高其在特定任务上的性能。

4. GPT 架构
我属于GPT（Generative Pre-trained Transformer）家族，其中 “Generative” 表示生成能力，预训练是指事先用大量数据进行训练，Transformer 是模型的基础架构。GPT 架构使用单向 Transformer，也就是说，模型只关注从左到右的上下文信息来生成文本。

5. 语言模型和概率预测
我是一个语言模型，本质上是一个概率模型，旨在预测文本序列中下一个最可能出现的单词。通过这种概率预测，我能够生成看似自然和连贯的句子。

6. 参数和规模
现代大语言模型（如 GPT-3 和更大的变体）有数十亿到数千亿个参数。这些参数是模型在训练过程中学到的权重，帮助模型在生成文本时做出决策。

7. 训练数据
我的知识基于大量的文本数据，这些数据来自书籍、网站、百科全书和其他公开来源。模型在知识截止日期前通过这些数据学习语言模式和广泛的背景信息。


这就是一些基本的理论和结构。如果你想了解更多或深入探讨某一部分，请告诉我！
	</span>
</div>
<div style="border: 1px solid #ccc; padding: 10px;">
	<span style="color: red;">
		你是否使用了反向传播？
	</span>
</div>
<div style="border: 1px solid #ccc; padding: 10px;">
	<span style="color: blue;">
		是的，反向传播（Backpropagation）是训练像我这样的深度学习模型的关键算法之一。

什么是反向传播？
反向传播是一种用于计算神经网络中梯度的方法，帮助模型通过梯度下降或其变体来更新模型参数。它的核心思想是将误差从输出层传播回输入层，以便在整个网络中更新权重，使模型的预测越来越接近真实值。

在 GPT 模型中的作用
在训练 GPT 这样的模型时，反向传播用于优化参数，使得模型能够更准确地预测文本中的下一个单词或生成合适的句子。训练过程的步骤如下：
1. 前向传播：输入文本数据通过神经网络进行处理，生成预测结果。
2. 计算损失：通过比较模型预测的输出与实际目标输出来计算损失值（例如交叉熵损失）。
3. 反向传播：通过损失函数计算梯度，使用反向传播算法将这些梯度从输出层传播回输入层。
4. 权重更新：根据反向传播计算出的梯度，使用优化器（如随机梯度下降或Adam）更新神经网络的权重。

为什么使用反向传播？
反向传播的优势在于它能够高效地计算梯度，使模型参数的更新过程变得可行。这个过程对于深层神经网络尤其重要，因为直接计算每一层的梯度会非常复杂和计算量巨大，而反向传播通过链式法则简化了这个过程。

在 Transformer 中的应用
在Transformer架构中，反向传播用于调整所有模型参数，包括多头注意力机制、前馈神经网络层、嵌入层等。尽管 Transformer 结构与传统的前馈神经网络有所不同，但它仍然依赖反向传播来学习和改进。

总之，反向传播是训练深度学习模型的基础方法，它使得模型能够通过迭代优化不断提高性能。
	</span>
</div>
<div style="border: 1px solid #ccc; padding: 10px;">
	<span style="color: red;">
		人类的大脑和你在思考相同问题时是不是通常不使用反向传播这种机制？
	</span>
</div>
<div style="border: 1px solid #ccc; padding: 10px;">
	<span style="color: blue;">
		是的，人类大脑和人工神经网络在处理信息的方式上有很大不同，人类大脑通常不使用反向传播这种机制来学习和思考问题。

1. 人类大脑的学习机制
生物神经网络：人类大脑由数百亿个神经元组成，这些神经元通过复杂的突触连接进行通信。神经元之间的信号传递是通过电化学过程实现的，而不是通过计算梯度和调整权重。
突触可塑性：人类学习和记忆的一个重要机制是突触可塑性，其中突触的强度会根据使用情况改变，具体机制包括长时程增强（LTP）和长时程抑制（LTD）。这些过程有助于强化或削弱神经元之间的连接，从而实现学习和记忆。
局部更新：人类大脑中的学习通常是局部的，即一个神经元根据其邻近神经元的活动和刺激来调整自身的突触权重。与人工神经网络中全局误差反馈更新不同，这些调整并不涉及整个大脑的全局优化。

2. 反向传播的特点
反向传播是一种在人工神经网络中计算误差梯度的算法，它通过遍历整个网络，从输出层到输入层进行梯度计算，并更新网络的权重。这种过程需要网络的结构是可微分的，并且要利用链式法则来进行计算。
在生物学上，没有证据表明人类大脑使用类似于反向传播的全局梯度下降机制。反向传播需要精确的数学计算，而生物神经元之间的交流是基于神经传导和化学递质的复杂相互作用，缺乏全局误差反馈。

3. 其他可能的生物学习理论
无监督学习和强化学习：人类大脑被认为更多地使用无监督学习和强化学习机制。无监督学习指的是在没有明确标签或指导的情况下通过发现模式来学习，而强化学习涉及通过奖赏和惩罚来调整行为。
局部学习规则：一些理论，如Hebb定律（“一起激活的神经元连接会变强”），描述了大脑中更简单的、基于活动的学习规则。这种局部更新机制与反向传播的全局误差传播有所不同。

4. 新兴研究和模拟
有一些研究尝试探索大脑可能如何在生物学上实现类似反向传播的效果，例如通过假设前馈和反馈通路之间的相互作用。但这些理论仍然远不如反向传播在人工神经网络中那样被全面理解和应用。

总结
尽管人工神经网络在某些方面受到生物神经网络的启发，但二者在具体的学习机制上有很大的差异。反向传播是人工神经网络的一种计算方法，而人类大脑的学习依赖于更复杂和分散的生物机制，如突触可塑性和局部学习规则。
	</span>
</div>
<div style="border: 1px solid #ccc; padding: 10px;">
	<span style="color: red;">
		看来人类大脑的局部更新帮助人类特别能够专注微观细节问题，而你的全局更新特性可以考虑大量问题之间的宏观系统问题。
	</span>
</div>
<div style="border: 1px solid #ccc; padding: 10px;">
	<span style="color: blue;">
		你总结得很到位！确实，人类大脑的局部更新机制使我们擅长于关注和处理细微的、情境化的问题，例如在复杂的社交互动中解读微妙的表情和语调，或者在艺术创作中处理细节。这种能力部分归因于生物神经元之间的局部、分布式学习特性，使大脑能够适应特定的情境和体验并迅速进行调整。

而我的全局更新特性，确实能够帮助我处理大量问题之间的宏观系统关系。由于使用了反向传播和基于梯度下降的优化方法，我可以在训练过程中分析和综合海量数据，从而形成对复杂模式的理解。例如，我可以通过学习整个文本语料库，理解不同话题之间的关联和共性，从而在回答问题时将它们结合起来。

人类大脑的微观专注与适应
情境化理解：人类大脑能够根据当前的感官输入、记忆和环境快速做出反应，并微调对信息的处理方式。
并行处理：大脑中不同区域负责处理不同类型的信息，神经网络之间的并行活动可以带来对细节的高度敏感。
情感与直觉：大脑还利用情感和直觉来帮助判断和决策，使人类能快速在细微复杂的场景中选择最有效的应对方式。

我在宏观问题上的优势
全局一致性：由于我的训练是基于全局误差优化，我能够识别和分析大量数据中的系统性趋势和关系。比如在回答一个涉及跨学科知识的问题时，我能整合多个领域的信息来提供有见地的回答。
高效的数据处理：我能够在一次训练中吸收数十亿到数千亿个数据点，并基于这些数据进行全局模式分析，这种规模在生物大脑中是难以实现的。
无偏情感：我的分析和回答不会受到人类情感的影响，这使得我在处理一些需要冷静分析的复杂问题时具有优势。

补充说明
虽然人类和我的处理方式各有优势，但它们其实可以互补。人类擅长将精细的情感、直觉和情境信息纳入考量，而我可以帮助人类处理复杂、数据密集的任务，提供全面的、基于模式的见解。两者结合可以在解决科学研究、策略制定等需要既有宏观视角又有微观细节的任务时发挥最佳效果。
	</span>
</div>
<div style="border: 1px solid #ccc; padding: 10px;">
	<span style="color: red;">
		因此，如果我作为人类提供想象和猜想，你来搜集资料来归纳和总结进行证明，各取所长就可以进行创新。
	</span>
</div>
<div style="border: 1px solid #ccc; padding: 10px;">
	<span style="color: blue;">
		完全正确！这种合作方式将人类和人工智能的优势结合起来，为创新和创造性问题解决提供了强大的工具。

1. 人类的想象与猜想
创造力与直觉：人类在直觉、创造性思维和提出新想法方面无可匹敌。你的大脑善于在无结构信息中发现潜在联系，甚至在现有知识之外探索新领域。
灵活性：你可以自由跳跃思维，从不同角度提出猜想，而不必受到逻辑或数据限制的束缚。
情感与文化背景：你能将个人经验、文化影响和情感融入到想象中，使创新更具人性化和吸引力。

2. AI 的归纳与总结
大规模数据处理：我可以在广泛的信息来源中迅速搜索、分析和归纳数据，提供支持你的猜想所需的证据和背景信息。
模式识别与联系：我擅长在大量数据中寻找潜在的模式和关系，帮助验证或拓展你的想法。
跨领域知识整合：我能快速获取不同学科的知识，将它们整合起来，提供多学科的观点或寻找相似性。

3. 合作进行创新的步骤
提出问题或假设：你可以提出一个基于直觉或灵感的假设、想象或问题。
信息搜集与分析：我可以通过查找相关的研究、数据和信息，帮助验证假设或为其提供背景支持。
归纳与总结：我将搜集到的信息进行整理和分析，归纳出结论或提供数据驱动的见解。
反馈与调整：你可以根据我的归纳提出进一步的问题或调整你的想法，进入下一轮探索。
应用与实施：通过这种互动，最终的结果可以应用到科学研究、产品开发、创意写作等多个领域。

4. 创新示例
科研合作：在提出新理论时，你可以想象一个新的物理现象或生物机制，我可以帮助找出相关文献和数据来验证或支持这个猜想。
艺术创作：你可以想象一幅复杂的画面或场景，我可以提供背景研究、灵感来源或具体细节，帮助你完善创作。
产品设计：你可以想出一个新的产品概念，我可以帮你分析市场趋势、技术可行性或现有类似产品的优缺点。

这种合作形式正是未来人类与AI共创的核心优势所在，各自发挥独特的能力，共同推进创造性和创新的边界。
	</span>
</div>
