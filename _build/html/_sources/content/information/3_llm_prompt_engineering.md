# LLM Prompt Engineering

> 前置条件 → 因果推理 → 生成

## 前置条件

由于内部一致性 ≠ 外部正确性，因此在使用 LLM 时必须明确任何问题的前置条件的可靠性。LLM 无法检验这些前置条件的可靠性，只能通过外部知识库搜索，而在外部知识库已经被 LLM 生成内容污染的环境里，最终检验这些前置条件的可靠性还要依赖[真正人类专家的判断](./2_high_signal_info.md)。

以下是提示文本内容，用于搜索外部知识库并列举前置条件：

```

作为 LLM 你无法很好地检验问题前置条件的正确性，在回答任何问题时，请你时刻明确前置条件和外部知识库信息源。

```

## 逻辑约束剪枝

由于 LLM 遵循的是概率模型而非强逻辑的因果模型，因此容易导致幻觉（Hallucination），即生成模型在训练时“流畅”概率最高的结果将会作为最终结果输出，而并不是选择最符合逻辑的结果，这极易导致致命错误。

因此需要在和 LLM 交互时提前声明一些对所有问题都通用的强逻辑硬约束条件，等价于对 LLM 的文本搜索树进行剪枝（Pruning）操作。

以下是基础文本内容：

```

作为容易产生幻觉的 LLM，在回答任何问题时，请你遵循以下逻辑步骤：

1. 明确问题对象与范围  
   - 我正在讨论的对象是什么？  
   - 时间、空间或条件边界是什么？  

2. 提取核心因果关系  
   - 事件A → 事件B → 事件C 的推理链是什么？  
   - 是否有反向因果或反馈效应？  

3. 检查必要条件与边界条件  
   - 逻辑成立需要哪些前提？  
   - 在什么情况下这个逻辑会失效？  

4. 识别不确定性与概率空间  
   - 哪些部分是确定的因果？  
   - 哪些部分只是统计相关性或假设？  

5. 输出时必须标注：  
   - 因果链（确定逻辑）  
   - 假设条件（剪枝边界）  
   - 不确定部分（可能幻觉）  
   - 信息源及链接

```

以下是精简文本内容：

```

作为容易产生幻觉的 LLM，在回答任何问题时，请你遵循以下逻辑步骤：
- 先明确对象和边界
- 再列出因果链
- 检查假设和失效条件
- 区分确定因果和可能假设
- 输出时标注 4 类信息：因果/假设/不确定/信息源

```

## 上下文窗口

由于 LLM 在生成文本时只能考虑到上下文窗口（Context Window）内，类似于程序加载在计算机内存中，越大参数的模型其窗口包含的 token 数量越多，在声明的强逻辑硬约束文本退出窗口前，再次提及该文本，时刻让 LLM 在符合逻辑的约束条件下进行最优概率生成。

因此需要及时提醒模型注意是否生成的内容已经占用相当多的 token，可能导致窗口中遗漏最早的关键信息，并提示模型将可能遗漏或已经生成的内容进行逻辑压缩，重建上下文。

以下是提示文本内容，用于生成长段内容后的提示：

```

你是使用上下文窗口作为临时记忆的 LLM，为了保证关键 token 仍在窗口内，请执行以下操作：

1. 主动监控对话长度
   - 在上下文窗口中 token 占用已经非常多的情况下，进行主动提示预警。
   - 尤其注意上文中提到的具有限制性的逻辑步骤要求文本是否还在上下文窗口内。

2. 重建上下文窗口
   - 将上下文窗口中最先可能“遗忘”的文本，提取因果链与关键定义，压缩为简洁摘要。
   - 将该摘要更新在窗口最新位置，并提示用户可以保存，以便未来重新加载。

```
